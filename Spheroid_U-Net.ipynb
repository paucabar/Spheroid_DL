{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate pytorchenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import RandomCrop\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'D:\\Institute of Genetics and Cancer\\Neurosphere assay\\Training_Data\\Images'\n",
    "label_path = r'D:\\Institute of Genetics and Cancer\\Neurosphere assay\\Training_Data\\LabelMasks'\n",
    "image_path = Path(image_path)\n",
    "image_path = sorted(list(Path(image_path).iterdir()))\n",
    "\n",
    "label_path = Path(label_path)\n",
    "label_path = sorted(list(Path(label_path).iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=[]\n",
    "for image in image_path:\n",
    "    img = io.imread(image)\n",
    "    all_images.append(img)\n",
    "\n",
    "all_labels=[]\n",
    "for label in label_path:\n",
    "    lbl = io.imread(label)\n",
    "    all_labels.append(lbl>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img_list,figsize=20,binaries=[],titles=[],**kwargs):\n",
    "\n",
    "    \"\"\"Display a list of images in horizontal subplots\"\"\"\n",
    "    assert type(img_list)==list\n",
    "    fig,axs=plt.subplots(1,len(img_list),figsize=(figsize,figsize))\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    plt.axes='off'\n",
    "    for i,img in enumerate(img_list):\n",
    "        if i in binaries:\n",
    "            im=axs[i].imshow(img,vmin=0,vmax=1,**kwargs)\n",
    "        else:\n",
    "            im=axs[i].imshow(img,**kwargs)\n",
    "        plt.colorbar(im, ax=axs[i],fraction=0.046, pad=0.04)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cropper = RandomCrop(size=512)\n",
    "blurrer = T.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))\n",
    "hflipper = T.RandomHorizontalFlip(p=0.5)\n",
    "vflipper = T.RandomVerticalFlip(p=0.5)\n",
    "    # custom dataset\n",
    "class CellDataset():\n",
    "    def __init__(self, images,labels, transforms=None):\n",
    "        self.X = images\n",
    "        self.Y=  labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = torch.Tensor(self.X[i]).half()\n",
    "        label=torch.Tensor(self.Y[i]).half()\n",
    "        stack=torch.stack((data,label))\n",
    "\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            data=1-data\n",
    "            #data=blurrer(data)\n",
    "            #pass\n",
    "\n",
    "        stack=cropper(stack)\n",
    "\n",
    "        # Increase the number of 'merged' objects calculating the maximum projection of the current crop\n",
    "        # and a crop genereted from a different, randomly selected image\n",
    "        # NOTE: brightfield images might not be suitable to apply this method\n",
    "\n",
    "        #if self.transforms:\n",
    "        #    nRandom = i\n",
    "        #    while nRandom == i:\n",
    "        #        nRandom = randrange(len(self.X)-1)\n",
    "            \n",
    "        #    stack2=torch.stack((torch.Tensor(self.X[nRandom]),torch.Tensor(self.Y[nRandom])))\n",
    "        #    stack = torch.maximum(stack, cropper(stack2))\n",
    "        #    stack[1]=stack[1]>0\n",
    "        #    show_images([stack[0], stack[1]])\n",
    "\n",
    "        if self.transforms:\n",
    "            stack=vflipper(stack)\n",
    "            stack=hflipper(stack)\n",
    "\n",
    "        data=stack[0][None,]\n",
    "        label=stack[1][None,].float()\n",
    "\n",
    "        return data.float(),label.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images([all_images[3],all_labels[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CellDataset(all_images[:10], all_labels[:10],transforms=True)\n",
    "test_data = CellDataset(all_images[10:], all_labels[10:],transforms=False)\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(next(iter(train_loader))[0][0][0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvSame(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(DoubleConvSame, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=c_out, out_channels=c_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(UNet, self).__init__()\n",
    " \n",
    "        self.conv1 = DoubleConvSame(c_in=c_in, c_out=64)\n",
    "        self.conv2 = DoubleConvSame(c_in=64, c_out=128)\n",
    "        self.conv3 = DoubleConvSame(c_in=128, c_out=256)\n",
    "        self.conv4 = DoubleConvSame(c_in=256, c_out=512)\n",
    "        #self.conv5 = DoubleConvSame(c_in=512, c_out=1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(\n",
    "            in_channels=1024, out_channels=512, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.up2 = nn.ConvTranspose2d(\n",
    "            in_channels=512, out_channels=256, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.up3 = nn.ConvTranspose2d(\n",
    "            in_channels=256, out_channels=128, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.up4 = nn.ConvTranspose2d(\n",
    "            in_channels=128, out_channels=64, kernel_size=2, stride=2\n",
    "        )\n",
    "\n",
    "     #   self.up_conv1 = DoubleConvSame(c_in=1024, c_out=512)\n",
    "        self.up_conv2 = DoubleConvSame(c_in=512, c_out=256)\n",
    "        self.up_conv3 = DoubleConvSame(c_in=256, c_out=128)\n",
    "        self.up_conv4 = DoubleConvSame(c_in=128, c_out=64)\n",
    "\n",
    "        self.conv_1x1 = nn.Conv2d(in_channels=64, out_channels=c_out, kernel_size=1)\n",
    "        self.norm=torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"ENCODER\"\"\"\n",
    "\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool(c1)\n",
    "\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool(c2)\n",
    "\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool(c3)\n",
    "\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool(c4)\n",
    "\n",
    "        \"\"\"BOTTLE-NECK\"\"\"\n",
    "\n",
    "      #  c5 = self.conv5(p4)\n",
    "\n",
    "        \"\"\"DECODER\"\"\"\n",
    "\n",
    "       # u1 = self.up1(c5)\n",
    "        #cat1 = torch.cat([u1, c4], dim=1)\n",
    "        uc1 = c4#.up_conv1(cat1)\n",
    "\n",
    "        u2 = self.up2(uc1)\n",
    "        cat2 = torch.cat([u2, c3], dim=1)\n",
    "        uc2 = self.up_conv2(cat2)\n",
    "\n",
    "       # print(uc2.shape)\n",
    "\n",
    "        u3 = self.up3(uc2)\n",
    "        cat3 = torch.cat([u3, c2], dim=1)\n",
    "        uc3 = self.up_conv3(cat3)\n",
    "       # print(uc3.shape)\n",
    "\n",
    "      # print(uc3.mean())\n",
    "\n",
    "        uc3=self.norm(uc3)\n",
    "\n",
    "       # print(uc3.mean())\n",
    "\n",
    "\n",
    "        u4 = self.up4(uc3)\n",
    "        cat4 = torch.cat([u4, c1], dim=1)\n",
    "        uc4 = self.up_conv4(cat4)\n",
    "\n",
    "       # print(uc4.shape)\n",
    "        outputs = self.conv_1x1(uc4)\n",
    "       # print(outputs.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        return sig(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=torch.load(\"myfirstunet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(output,target):\n",
    "    loss=(output-target)**2\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=UNet(1,1).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "sig = nn.Sigmoid()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(NN, device, dataloader, loss_fn, optimizer):\n",
    "    NN.train()\n",
    "    train_loss = []\n",
    "    for image_batch,labels_batch, in dataloader:\n",
    "        imgs=image_batch.to(device)\n",
    "        labels=labels_batch.to(device)\n",
    "        output = NN(-imgs)\n",
    "        loss =loss_fn(sig(output),labels.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    img1=imgs.detach().cpu().numpy()[0][0]\n",
    "    label1=labels.detach().cpu().numpy()[0][0]\n",
    "    output1=output.detach().cpu().numpy()[0][0]\n",
    "    #show_images([img1,label1,output1],binaries=[])\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def test_epoch(NN, device, dataloader, loss_fn, optimizer):\n",
    "    NN.eval()\n",
    "    test_loss = []\n",
    "    for image_batch,labels_batch, in dataloader:\n",
    "        imgs=image_batch.to(device)\n",
    "        labels=labels_batch.to(device)#.squeeze(1)\n",
    "        output = NN(imgs)\n",
    "        loss = loss_fn(sig(output),labels.float())\n",
    "        test_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    img1=imgs.detach().cpu().numpy()[0][0]\n",
    "    label1=labels.detach().cpu().numpy()[0][0]\n",
    "    output1=output.detach().cpu().numpy()[0][0]\n",
    "\n",
    "    #show_images([img1,label1,output1],binaries=[])\n",
    "   # print(loss)\n",
    "\n",
    "    return np.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "test_loss=[]\n",
    "for epoch in tqdm(range(500)):\n",
    "    train_loss.append(train_epoch(model, device, train_loader, loss_fn, optimizer))\n",
    "    test_loss.append(test_epoch(model, device, test_loader, loss_fn, optimizer))\n",
    "    print(\"Train loss\",train_loss[-1])\n",
    "    print(\"Test loss\",test_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label=\"train\")\n",
    "plt.plot(test_loss,label=\"test\")\n",
    "plt.ylim(0.67,0.75)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"myfirstunet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') /w\n",
    "    \n",
    "def plot_average(train,test,clip=99,window_size=100):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    clip_val=np.percentile(test,[clip])\n",
    "    test=np.clip(test,0,clip_val[0])\n",
    "    clip_val=np.percentile(train,[clip])\n",
    "    train=np.clip(train,0,clip_val[0])\n",
    "    plt.plot(moving_average(test,window_size),label=\"test\")\n",
    "    plt.plot(moving_average(train,window_size),label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average(train_loss, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d12ee0532f5fe809fea6ed49d84e6d6e9be1b8657fb8079f6358b85f8ed0388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
